# ðŸ§  Real-Time Edge Detection Viewer

A cross-platform **real-time edge detection viewer** built using **Android (Kotlin + OpenCV + OpenGL ES)** and a **TypeScript-based web viewer**.  
Captures camera frames, processes them in **C++ via JNI**, renders them with **OpenGL ES**, and displays a static frame on a **web page**.

---

## âœ… Features Implemented

### Android Features

| Feature | Description |
|---------|-------------|
| ðŸ“· **Camera Feed Capture** | Captures live frames using **Camera2 API** and displays them on a `TextureView`. |
| âš™ï¸ **OpenCV Processing (C++)** | Applies **Canny Edge Detection** or **Grayscale** via JNI using native C++ code in `jni/`. |
| ðŸŽ¨ **OpenGL ES Rendering** | Renders processed frames as textures using **GLRenderer** from `gl/`. |
| ðŸŸ¢ **Feed Toggle** | Switch between raw camera feed and processed (edge-detected) output. |

### Web Features

| Feature | Description |
|---------|-------------|
| ðŸ’» **Web Viewer** | Displays a static processed frame from the Android app (saved as base64) using **TypeScript + HTML**. |
| ðŸŒ **Mock Server** | Simple mock endpoint serves frames to the web viewer for visualization or debugging. |

### Bonus Features Implemented

- ðŸŽ­ **OpenGL Shaders** â€“ Apply optional visual effects like grayscale or invert.  
- ðŸŒ **Web Integration** â€“ Optional real-time frame export to the web viewer.  

---

## ðŸ“· Screenshots / GIF

*Include your app screenshots or GIF here.*

Example placeholder:

![App Screenshot](web/static/sample_frame.png)

---

## âš™ Setup Instructions (Android + Web, NDK & OpenCV)

### 1ï¸âƒ£ Prerequisites

- **Android Studio** (latest stable)  
- **Android SDK & NDK** installed (ensure NDK path set in Android Studio: `File â†’ Project Structure â†’ SDK Location â†’ NDK`)  
- **OpenCV Android SDK** installed (set correct path in `CMakeLists.txt` and Gradle)  
- **local.properties** file must include paths for SDK, NDK, and OpenCV:
  ```properties
  sdk.dir=/path/to/android/sdk
  ndk.dir=/path/to/android/ndk
  opencv.dir=/path/to/OpenCV-android-sdk
  ```
- **Node.js & npm** (for web viewer)  
- USB Debugging enabled on Android device

> **Note:** Verify that NDK version matches Gradle `externalNativeBuild` configuration and OpenCV include/lib paths are correct.

---

### 2ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/tanuku-saikarthik/Real-Time-Edge-Detection-Viewer.git
cd Real-Time-Edge-Detection-Viewer
```

---

### 3ï¸âƒ£ Android Studio Setup (Including NDK, OpenCV & local.properties)

1. **Open Project**  
   - Open Android Studio â†’ *Open Existing Project* â†’ select `app/`.

2. **Move Native Code** (Optional, for conventional Android Studio structure)

```bash
mkdir -p app/src/main/cpp
mv jni app/src/main/cpp/
mv gl app/src/main/cpp/
```

3. **Update CMakeLists.txt**  
Ensure OpenCV paths are set correctly using `local.properties` if needed:

```cmake
add_library(edge_detector SHARED
    app/src/main/cpp/jni/edge_detector.cpp
    app/src/main/cpp/gl/gl_renderer.cpp
)

# Include OpenCV SDK headers
include_directories(${OpenCV_INCLUDE_DIRS})
link_directories(${OpenCV_LIB_DIR})
target_link_libraries(edge_detector ${OpenCV_LIBS})
```

4. **Update `app/build.gradle.kts`**

```kotlin
android {
    ...
    externalNativeBuild {
        cmake {
            path = file("../jni/CMakeLists.txt")
            version = "3.22.1"
        }
    }
}
```

5. **Sync Gradle**  
   - Click **File â†’ Sync Project with Gradle Files**.  
   - Ensure NDK, OpenCV paths, and local.properties values are detected correctly.

6. **Connect Device & Run**  
   - Enable USB debugging.  
   - Click **Run â†’ App** (Shift+F10).  
   - Check **Logcat** for native logs confirming OpenCV initialization and rendering.

---

### 4ï¸âƒ£ Build & Run via Terminal (Optional â€” No folder restructuring or path adjustments needed)

```bash
# Assemble APK
./gradlew assembleDebug

# Install APK
./gradlew installDebug

# Launch App
adb shell am start -n com.karthik.edgedemo/.MainActivity
```

---

### 5ï¸âƒ£ Web Viewer Setup

```bash
cd web
npm install
npm run start
```

Opens a browser page showing a static processed frame.

---

### âœ… Verification Checklist

| Step | What to Check |
|------|---------------|
| ðŸ§© NDK & OpenCV Paths | App builds without native errors |
| ðŸŽ¨ OpenGL Renderer | Frames render smoothly with edges |
| ðŸ§® JNI Bridge | Logs show â€œJNI initializedâ€ |
| ðŸŒ Web Viewer | Web page loads the static frame successfully |


## ðŸ§  Architecture Overview

### System Flow

```mermaid
flowchart TD
    A[ðŸ“± Android Camera Feed] -->|Captured Frame| B[ðŸ”— JNI Bridge]
    B -->|Passes Frame| C[âš™ï¸ Native C++ Layer]
    C -->|OpenCV Processing| D[ðŸ§  Edge Detection / Grayscale]
    D -->|Processed Frame| E[ðŸŽ¨ OpenGL ES Renderer]
    E -->|Renders Texture| F[ðŸ“² Android App UI]

```

### Component Hierarchy

```mermaid
flowchart TD
 subgraph subGraph0["Android App"]
        UI["ðŸ“± Kotlin UI / TextureView"]
        Camera["ðŸ“· Camera2 API"]
        JNI["ðŸ”— JNI Bridge"]
        OpenGL["ðŸŽ¨ OpenGL ES Renderer"]
  end
 subgraph subGraph1["Native Layer"]
        Cpp["âš™ï¸ C++ + OpenCV Processing"]
        Shaders["ðŸŽ­ Optional GLSL Shaders"]
  end
 subgraph subGraph2["Web Viewer"]
        WebPage["ðŸ’» TypeScript + HTML"]
        WebFrame["ðŸ–¼ Dummy/Static Frame Display"]
  end
    Camera --> UI
    UI --> JNI
    JNI --> Cpp
    Cpp --> OpenGL & Shaders
    OpenGL --> UI
    WebFrame --> WebPage
```

**Explanation:**  
- **Android App:** Captures frames â†’ JNI â†’ renders via OpenGL ES.  
- **Native Layer:** Processes frames in C++ with OpenCV, optionally applies shaders.  
- **Web Viewer:** Displays dummy/static frames using TypeScript + HTML.

---

### ðŸ”§ Tech Stack

- **Android:** Kotlin, Camera2 API, NDK, JNI  
- **Native:** C++ + OpenCV  
- **Rendering:** OpenGL ES 2.0, GLSL shaders  
- **Web:** TypeScript, HTML, Node.js

